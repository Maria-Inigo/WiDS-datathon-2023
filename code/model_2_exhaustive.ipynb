{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bce1d0a5",
   "metadata": {},
   "source": [
    "#### CRISP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19e83e3a",
   "metadata": {},
   "source": [
    "## Business Understanding\n",
    "\n",
    "- There are 2 datasets train_data.csv and test_data.csv\n",
    "- The contest-tmp2m-14d__tmp2m is the mean (tmax+tmin / 2) temperature and is to be predicted for the test data\n",
    "- Latitude and longitude are anonymized so latitude information cannot be used for temperature prediction\n",
    "- startdate indicates the start of a 14 day period\n",
    "- The data provided is between 2014 and 2016, therefore the affect of El Nino is to be considered\n",
    "- nmme forecast values and other forecast values will not be part of the feature set used for this model\n",
    "- The 2010 data for geopotential, wind, etc. will also be discarded for this model\n",
    "- The 2010 data for sea surface temperature will be however used"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "990ed2b4",
   "metadata": {},
   "source": [
    "## Data Analysis"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2a05a6a2",
   "metadata": {},
   "source": [
    "#### Import libraries and set Universal params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d1b6155",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import main libraries for data analysis and modelling\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "# Import additional helper libraries\n",
    "import os\n",
    "import datetime as dt\n",
    "from IPython.display import display\n",
    "from math import radians, cos, sin, asin, sqrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eb3ac23",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max.columns\", None)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c7d3a477",
   "metadata": {},
   "source": [
    "#### Set paths and create dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab3a3109",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the filepath\n",
    "\n",
    "data_dir = os.path.abspath(os.path.join(os.getcwd(), os.pardir)) + '/data/'\n",
    "\n",
    "train_csv = data_dir + 'train_data.csv'\n",
    "test_csv = data_dir + 'test_data.csv'\n",
    "\n",
    "print(train_csv)\n",
    "print(test_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c58395",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the training data set\n",
    "train_df_raw = pd.read_csv(train_csv)\n",
    "\n",
    "# Load the test data set\n",
    "test_df_raw = pd.read_csv(test_csv)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0580f858",
   "metadata": {},
   "source": [
    "#### Initial Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d6a0fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(train_df_raw.info())\n",
    "display(train_df_raw.head())\n",
    "display(train_df_raw.tail())\n",
    "display(train_df_raw.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad79c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('train_columns.txt', 'w', encoding='utf-8') as f:\n",
    "    for col in train_df_raw.columns:\n",
    "        f.write(f'{col},{train_df_raw.dtypes[col]},{len(train_df_raw[col].unique())}\\n')\n",
    "\n",
    "with open('train_df_info.txt', 'w', encoding='utf-8') as f:\n",
    "    train_df_raw.info(verbose=True, buf=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa78a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find any column with empty/null values\n",
    "print(f'Columns with null vaules in Training data are {train_df_raw.columns[train_df_raw.isnull().any()]}')\n",
    "\n",
    "# Find the target column\n",
    "target_column = train_df_raw.columns.difference(test_df_raw.columns)[0]\n",
    "print(f'The target column for prediction is {target_column}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e72fc4a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get current precision of latitude and longitude\n",
    "loc_data = train_df_raw[['lat','lon']]\n",
    "precision = loc_data.applymap(lambda x: len(str(x).split('.')[1]))\n",
    "\n",
    "print(f'Current precision of latitude in training data is {precision.lat.max()}')\n",
    "print(f'Current precision of longitude in training data is {precision.lon.max()}')\n",
    "\n",
    "loc_data = test_df_raw[['lat','lon']]\n",
    "precision = loc_data.applymap(lambda x: len(str(x).split('.')[1]))\n",
    "\n",
    "print(f'Current precision of latitude in test data is {precision.lat.max()}')\n",
    "print(f'Current precision of longitude in test data is {precision.lon.max()}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e983abe4",
   "metadata": {},
   "source": [
    "##### Initial Data Transformations\n",
    "Needed for the data to be properly visualized. E.g. Convert startdate from mm/dd/yy to ISO format; Sorting by location and date; Combine the latitude and longitude to create location; Reduce the precision of latitude and longitude to 14 to omit superfluous locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2e91b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new copies of the dataframes for further operations\n",
    "train_df = train_df_raw\n",
    "test_df = test_df_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f1f3a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['startdate'] = pd.to_datetime(train_df['startdate'], format='%m/%d/%y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fd498ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df.sort_values(by='startdate',inplace=True)\n",
    "train_df['startdate'].is_monotonic_increasing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18544c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add standard 15 digit decimal places precision to latitude and longitude\n",
    "# There is some trial and error involved here to get combined common locations in the following 4 code snippets\n",
    "train_df['lat'] = train_df['lat'].round(14)\n",
    "train_df['lon'] = train_df['lon'].round(14)\n",
    "test_df['lat'] = test_df['lat'].round(14)\n",
    "test_df['lon'] = test_df['lon'].round(14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba22b2c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to combine the latitude and longitude for easier data handling\n",
    "# 'Single-point' Haversine: Calculates the great circle distance between a point on Earth and the (0, 0) lat-long coordinate\n",
    "\n",
    "def single_pt_haversine(lat, lon, degrees=True):\n",
    "    \n",
    "    r = 6371 # Earth's radius (km)\n",
    "\n",
    "    # Convert decimal degrees to radians\n",
    "    if degrees:\n",
    "        lat, lon = map(radians, [lat, lon])\n",
    "\n",
    "    # 'Single-point' Haversine formula\n",
    "    a = sin(lat/2)**2 + cos(lat) * sin(lon/2)**2\n",
    "    d = 2 * r * asin(sqrt(a)) \n",
    "\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b5d3b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine latitude and longitude to generate unique geolocations\n",
    "\n",
    "train_df['haversine_distance'] = [single_pt_haversine(x, y) for x, y in zip(train_df.lat, train_df.lon)]\n",
    "print(f'There are {train_df.haversine_distance.nunique()} unique locations in training data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "733737d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['haversine_distance'] = [single_pt_haversine(x, y) for x, y in zip(test_df.lat, test_df.lon)]\n",
    "print(f'There are {test_df.haversine_distance.nunique()} unique locations in test data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a15d4218",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get unique locations by combining test and training data and grouping by latitude and longitude\n",
    "combined_data = pd.concat([train_df,test_df], axis=0)\n",
    "combined_data['haversine_distance'] = [single_pt_haversine(x, y) for x, y in zip(combined_data.lat, combined_data.lon)]\n",
    "print(f'There are {combined_data.haversine_distance.nunique()} unique locations in combined data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a353197",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c1369a2f",
   "metadata": {},
   "source": [
    "#### Visualize Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "299fd146",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0400ba89",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "633ce6e2",
   "metadata": {},
   "source": [
    "## Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d52b99c",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "vscode": {
   "interpreter": {
    "hash": "c261aea317cc0286b3b3261fbba9abdec21eaa57589985bb7a274bf54d6cc0a7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
