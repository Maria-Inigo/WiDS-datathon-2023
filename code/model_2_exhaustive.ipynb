{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bce1d0a5",
   "metadata": {},
   "source": [
    "#### CRISP"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "19e83e3a",
   "metadata": {},
   "source": [
    "## Business Understanding\n",
    "\n",
    "- There are 2 datasets `train_data.csv` and `test_data.csv`\n",
    "- The `contest-tmp2m-14d__tmp2m` is the mean `(tmax+tmin / 2)` temperature and is to be predicted for the test data\n",
    "- Latitude and longitude are anonymized so latitude information cannot be used for temperature prediction\n",
    "- `startdate` indicates the start of a 14 day period\n",
    "- The data provided is between **2014** and **2016**, therefore the affect of **El Nino** is to be considered\n",
    "- `nmme` forecast values and other forecast values will not be part of the feature set used for this model\n",
    "- The 2010 data for geopotential, wind, etc. will also be discarded for this model\n",
    "- The 2010 data for sea surface temperature will be however used"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "581d86dd",
   "metadata": {},
   "source": [
    "NOTE: *There are inferences below some of the data analysis/visualization which dictates the next set of data transformations*"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "990ed2b4",
   "metadata": {},
   "source": [
    "## Data Analysis"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2a05a6a2",
   "metadata": {},
   "source": [
    "#### Import libraries and set Universal params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d1b6155",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import main libraries for data analysis and modelling\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.feature_selection import SelectKBest, chi2, f_regression, f_classif, mutual_info_classif, SelectFromModel, RFE\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "from mpl_toolkits import mplot3d\n",
    "import plotly.express as px\n",
    "\n",
    "# Import additional helper libraries\n",
    "import os\n",
    "import datetime as dt\n",
    "from IPython.display import display\n",
    "# import math\n",
    "# from math import radians, cos, sin, asin, sqrt\n",
    "# import itertools\n",
    "from shapely.geometry import Point\n",
    "from shapely import wkt\n",
    "import geopandas as gpd\n",
    "from geopandas import GeoDataFrame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eb3ac23",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max.columns\", None)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c7d3a477",
   "metadata": {},
   "source": [
    "#### Set paths and create dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab3a3109",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the filepath\n",
    "\n",
    "data_dir = os.path.abspath(os.path.join(os.getcwd(), os.pardir)) + '/data/'\n",
    "\n",
    "train_csv = data_dir + 'train_data.csv'\n",
    "test_csv = data_dir + 'test_data.csv'\n",
    "\n",
    "print(train_csv)\n",
    "print(test_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c58395",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the training data set\n",
    "train_df_raw = pd.read_csv(train_csv)\n",
    "\n",
    "# Load the test data set\n",
    "test_df_raw = pd.read_csv(test_csv)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0580f858",
   "metadata": {},
   "source": [
    "#### Initial Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d6a0fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display primary observations\n",
    "display(train_df_raw.info())\n",
    "display(train_df_raw.head())\n",
    "display(train_df_raw.tail())\n",
    "display(train_df_raw.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad79c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('train_columns.txt', 'w', encoding='utf-8') as f:\n",
    "    for col in train_df_raw.columns:\n",
    "        f.write(f'{col},{train_df_raw.dtypes[col]},{len(train_df_raw[col].unique())}\\n')\n",
    "\n",
    "with open('train_df_info.txt', 'w', encoding='utf-8') as f:\n",
    "    train_df_raw.info(verbose=True, buf=f)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8862b839",
   "metadata": {},
   "source": [
    "- `startdate` is an object and needs to be converted to `datetime` and later to `ordinal` Int type for usability\n",
    "- `climateregions__climateregion` is an object and needs to be converted to string type for usability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f14a61f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the target column\n",
    "target_feature = train_df_raw.columns.difference(test_df_raw.columns)[0]\n",
    "print(f'The target feature for prediction is {target_feature}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa78a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find any column with empty/null values\n",
    "\n",
    "null_features = train_df_raw.columns[train_df_raw.isnull().any()] \n",
    "nan_features = train_df_raw.columns[train_df_raw.isna().any()]\n",
    "\n",
    "print(f'Columns with null vaules in Training data are {train_df_raw.columns[train_df_raw.isnull().any()]}')\n",
    "print(f'Columns with null vaules in Training data are {train_df_raw.columns[train_df_raw.isna().any()]}')\n",
    "\n",
    "def get_null_percentage(df):\n",
    "    null_counts = df.isnull().sum()\n",
    "    null_percentage = null_counts / df.shape[0] * 100\n",
    "    return {'null_counts': null_counts, 'null_percentage': null_percentage}\n",
    "\n",
    "for nf in nan_features:\n",
    "    print(nf,get_null_percentage(train_df_raw[nf]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "24511eca",
   "metadata": {},
   "source": [
    "- Use **Imputer** to populate the `NaN` data\n",
    "- Null percentage is small so could be imputed using mean/mode\n",
    "- The features having `null/NaN` value are all prediction data and hence could be ignored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9991e4a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check unique locations\n",
    "print('Unique locations in train data ',train_df_raw.groupby(['lat','lon']).ngroup().nunique())\n",
    "print('Unique locations in test data ',test_df_raw.groupby(['lat','lon']).ngroup().nunique()) \n",
    "print('Unique locations in combined data ',pd.concat([train_df_raw,test_df_raw], axis=0).groupby(['lat','lon']).ngroup().nunique())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2793b218",
   "metadata": {},
   "source": [
    "Combined dataframe gives more unique locations than either train or test data. Check precision of location data to determine practicality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e72fc4a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get current precision of latitude and longitude\n",
    "precision = train_df_raw[['lat','lon']].applymap(lambda x: len(str(x).split('.')[1]))\n",
    "\n",
    "print(f'Current precision of latitude in training data is {precision.lat.max()}')\n",
    "print(f'Current precision of longitude in training data is {precision.lon.max()}')\n",
    "\n",
    "precision = test_df_raw[['lat','lon']].applymap(lambda x: len(str(x).split('.')[1]))\n",
    "\n",
    "print(f'Current precision of latitude in test data is {precision.lat.max()}')\n",
    "print(f'Current precision of longitude in test data is {precision.lon.max()}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "60265a09",
   "metadata": {},
   "source": [
    "- Precision 16 is too high for practical purpose. This indicates a computer or calculator was used and that no attention was paid to the fact that the extra decimals are useless.\n",
    "- The ninth decimal place is worth up to 110 microns. So, this is getting into the range of microscopy. \n",
    "- For almost any conceivable application with earth positions, this is overkill and will be more precise than the accuracy of any surveying device.\n",
    "- Decision is to reduce precision to 6 decimal places"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c35417",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will simply check whether a column is sorted. This is done as is_monotonic is deprecated\n",
    "def check_sort(df,col):\n",
    "    if df[col].is_monotonic_increasing or df[col].is_monotonic_decreasing:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35638aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the current sorting order on important columns\n",
    "print('Sorted by index = ', check_sort(train_df_raw,'index'))\n",
    "print('Sorted by latitude = ', check_sort(train_df_raw,'lat'))\n",
    "print('Sorted by longitude = ', check_sort(train_df_raw,'lon'))\n",
    "print('Sorted by date = ', check_sort(train_df_raw,'startdate'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4062b36a",
   "metadata": {},
   "source": [
    "A useful sorting would be to sort by location (combined latitude and longitude) and then by date"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "227691d3",
   "metadata": {},
   "source": [
    "##### Raw Data Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd894309",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check initial locations on a map to understand the geography of train data\n",
    "location_df = train_df_raw[['lat','lon']].drop_duplicates().copy()\n",
    "location_df.head()\n",
    "\n",
    "geometry = [Point(xy) for xy in zip(location_df['lat'], location_df['lon'])]\n",
    "gdf = GeoDataFrame(location_df, geometry=geometry)   \n",
    "\n",
    "#this is a simple map that goes with geopandas\n",
    "world = gpd.read_file(gpd.datasets.get_path('naturalearth_lowres'))\n",
    "gdf.plot(ax=world.plot(figsize=(10, 6)), marker='o', color='red', markersize=1);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f2c3264",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check initial locations on a map to understand the geography of test data\n",
    "location_df = test_df_raw[['lat','lon']].drop_duplicates().copy()\n",
    "location_df.head()\n",
    "\n",
    "geometry = [Point(xy) for xy in zip(location_df['lat'], location_df['lon'])]\n",
    "gdf = GeoDataFrame(location_df, geometry=geometry)   \n",
    "\n",
    "#this is a simple map that goes with geopandas\n",
    "world = gpd.read_file(gpd.datasets.get_path('naturalearth_lowres'))\n",
    "gdf.plot(ax=world.plot(figsize=(10, 6)), marker='o', color='red', markersize=1);\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c6c6339f",
   "metadata": {},
   "source": [
    "- Both train and test data are supposedly at the same location.\n",
    "- `Location` is anonymized therefore it could be either omitted or converted to categorical feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90c6b11b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the spread of time in train and test data\n",
    "time_df_train = pd.DataFrame()\n",
    "time_df_train['startdate'] = pd.to_datetime(train_df_raw['startdate'], format='%m/%d/%y')\n",
    "\n",
    "time_df_test = pd.DataFrame()\n",
    "time_df_test['startdate'] = pd.to_datetime(test_df_raw['startdate'], format='%m/%d/%y')\n",
    "\n",
    "fig, ax = plt.subplots(1,1, figsize=(16,2))\n",
    "ax.set_title('Time Series Data')\n",
    "\n",
    "sns.scatterplot(data = time_df_train, x = 'startdate', y = 1, marker='o', linewidth=0, label = 'train')\n",
    "sns.scatterplot(data = time_df_test, x = 'startdate', y = 1, marker='o', linewidth=0, label = 'test')\n",
    "\n",
    "ax.set_xlim([time_df_train['startdate'].iloc[0], time_df_test['startdate'].iloc[-1]])\n",
    "plt.show()\n",
    "\n",
    "time_df_train.groupby([time_df_train['startdate'].dt.year, time_df_train['startdate'].dt.month]).count().plot(kind='bar')\n",
    "time_df_test.groupby([time_df_test['startdate'].dt.year, time_df_test['startdate'].dt.month]).count().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "619166d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize target temperature \n",
    "temp_df = train_df_raw[['lat','lon','startdate','contest-tmp2m-14d__tmp2m']].copy()\n",
    "temp_df['startdate'] = pd.to_datetime(temp_df['startdate'], format='%m/%d/%y')\n",
    "temp_df['location'] = [Point(xy) for xy in zip(temp_df['lat'], temp_df['lon'])] \n",
    "temp_df['location_str'] = temp_df['location'].apply(lambda x: wkt.dumps(x)) # Testing Point geometry to String for use in ML training\n",
    "\n",
    "temp_df = temp_df.pivot(index='startdate', columns='location_str', values='contest-tmp2m-14d__tmp2m')\n",
    "temp_df.head()\n",
    "temp_df.plot(legend=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "487a0c89",
   "metadata": {},
   "source": [
    "- The temperature spread is even and reasoanable across the year matching the northern hemisphere seasonal temperature variation\n",
    "- The temperature spread by location indicates the locations to be spread across a large geographical area and multiple climatic regions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e983abe4",
   "metadata": {},
   "source": [
    "#### Initial Data Transformations\n",
    "Needed for the data to be properly visualized. E.g. Convert startdate from mm/dd/yy to ISO format; Sorting by location and date; Combine the latitude and longitude to create location; Reduce the precision of latitude and longitude to 6 to omit superfluous locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bc822ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temporary functions to test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2e91b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new copies of the dataframes for further operations\n",
    "train_df = train_df_raw.copy()\n",
    "test_df = test_df_raw.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f1f3a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert startdate from object to various usable types. Month of the year has more impact on weather so Year, Month and Day will be separated\n",
    "train_df['startdate'] = pd.to_datetime(train_df['startdate'], format='%m/%d/%y')\n",
    "train_df['startdate_ordinal'] = train_df['startdate'].apply(lambda x:x.toordinal())\n",
    "train_df['year'] = train_df['startdate'].dt.year\n",
    "train_df['month'] = train_df['startdate'].dt.month\n",
    "train_df['dayofyear'] = train_df['startdate'].dt.day_of_year\n",
    "\n",
    "test_df['startdate'] = pd.to_datetime(test_df['startdate'], format='%m/%d/%y')\n",
    "test_df['startdate_ordinal'] = test_df['startdate'].apply(lambda x:x.toordinal())\n",
    "test_df['year'] = test_df['startdate'].dt.year\n",
    "test_df['month'] = test_df['startdate'].dt.month\n",
    "test_df['dayofyear'] = test_df['startdate'].dt.day_of_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18544c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Round to 6 decimal places precision to latitude and longitude for all practical purpose\n",
    "scale = 6\n",
    "train_df['lat'] = train_df['lat'].round(scale)\n",
    "train_df['lon'] = train_df['lon'].round(scale)\n",
    "test_df['lat'] = test_df['lat'].round(scale)\n",
    "test_df['lon'] = test_df['lon'].round(scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66190de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Unique locations in train data ',train_df.groupby(['lat','lon']).ngroup().nunique())\n",
    "print('Unique locations in test data ',test_df.groupby(['lat','lon']).ngroup().nunique()) \n",
    "print('Unique locations in combined data ',pd.concat([train_df,test_df], axis=0).groupby(['lat','lon']).ngroup().nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba22b2c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For now Haversine distance will not be used, instead Point geometry data for location will be converted to string for use as classification feature\n",
    "\n",
    "# Need to combine the latitude and longitude for easier data handling\n",
    "# 'Single-point' Haversine: Calculates the great circle distance between a point on Earth and the (0, 0) lat-long coordinate\n",
    "\n",
    "# def single_pt_haversine(lat, lon, degrees=True):\n",
    "    \n",
    "#     r = 6371 # Earth's radius (km)\n",
    "\n",
    "#     # Convert decimal degrees to radians\n",
    "#     if degrees:\n",
    "#         lat, lon = map(radians, [lat, lon])\n",
    "\n",
    "#     # 'Single-point' Haversine formula\n",
    "#     a = sin(lat/2)**2 + cos(lat) * sin(lon/2)**2\n",
    "#     d = 2 * r * asin(sqrt(a)) \n",
    "\n",
    "#     return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b5d3b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine latitude and longitude to generate unique geolocations. Convert to String for later use\n",
    "\n",
    "# train_df['haversine_distance'] = [single_pt_haversine(x, y) for x, y in zip(train_df.lat, train_df.lon)]\n",
    "train_df['location'] = [Point(xy) for xy in zip(train_df['lat'], train_df['lon'])] \n",
    "train_df['location'] = train_df['location'].apply(lambda x: wkt.dumps(x))\n",
    "\n",
    "test_df['location'] = [Point(xy) for xy in zip(test_df['lat'], test_df['lon'])] \n",
    "test_df['location'] = test_df['location'].apply(lambda x: wkt.dumps(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "733737d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if data is sorted by new location information\n",
    "print('Sorted by Location = ', check_sort(train_df,'location'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f46a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('locations.txt', 'w', encoding='utf-8') as f:\n",
    "    for e in list(train_df['location'].unique()):\n",
    "        f.write(f'{e}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f79ada24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Climate regions to string and dummy numerical data for processing\n",
    "train_df['climateregions__climateregion'] = train_df['climateregions__climateregion'].astype(str)\n",
    "train_df['climateregions_num'] = LabelEncoder().fit_transform(train_df['climateregions__climateregion'])\n",
    "\n",
    "test_df['climateregions__climateregion'] = test_df['climateregions__climateregion'].astype(str)\n",
    "test_df['climateregions_num'] = LabelEncoder().fit_transform(test_df['climateregions__climateregion'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e025fc2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute Null/NaN values\n",
    "imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "imputer = imputer.fit(train_df[nan_features])\n",
    "  \n",
    "train_df[nan_features] = imputer.transform(train_df[nan_features])\n",
    "print(f'Columns with null vaules in Training data are {train_df.columns[train_df.isnull().any()]}')\n",
    "print(f'Columns with null vaules in Training data are {train_df.columns[train_df.isna().any()]}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c1369a2f",
   "metadata": {},
   "source": [
    "#### Further analyse and Visualize Data "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "306770ee",
   "metadata": {},
   "source": [
    "##### Feature Selection Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e5d41c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# features that are non-numeric\n",
    "nonum_features = ['location','startdate','startdate_ordinal','climateregions__climateregion','lat','lon','index']\n",
    "\n",
    "# features that are predictions from other models\n",
    "all_features = list(train_df.columns)\n",
    "predict_prefix = ('nmme','cancm','ccsm','cfsv20','gfdl','nasa')\n",
    "\n",
    "predict_features = []\n",
    "for f in all_features:\n",
    "    if f.startswith(predict_prefix):\n",
    "        predict_features.append(f)\n",
    "print(predict_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95bbd2b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Univariate Selection to identify strongest relationship to target\n",
    "features_to_drop = nonum_features + predict_features\n",
    "features_to_drop.append(target_feature)\n",
    "\n",
    "X = train_df.copy()\n",
    "X = X.drop(features_to_drop, axis=1)\n",
    "y = train_df[target_feature].copy()\n",
    "\n",
    "selector = SelectKBest(f_regression, k=10) # Top 30 features\n",
    "selector.fit(X, y)\n",
    "scores = selector.scores_\n",
    "\n",
    "bestfeatures = pd.DataFrame({'feature': X.columns, 'score': scores})\n",
    "bestfeatures = bestfeatures.sort_values(by='score', ascending=False)\n",
    "\n",
    "display(bestfeatures.head(10))\n",
    "bestfeatures.plot.bar(x='feature', y='score',figsize=(70, 20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00358258",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANOVA F-value to identify important features\n",
    "features_to_drop = nonum_features + predict_features\n",
    "features_to_drop.append(target_feature)\n",
    "\n",
    "X = train_df.copy()\n",
    "X = X.drop(features_to_drop, axis=1)\n",
    "y = train_df[target_feature].copy()\n",
    "\n",
    "selector = SelectKBest(f_classif, k=10) # Top 30 features\n",
    "selector.fit(X, y)\n",
    "scores = selector.scores_\n",
    "\n",
    "bestfeatures = pd.DataFrame({'feature': X.columns, 'score': scores})\n",
    "bestfeatures = bestfeatures.sort_values(by='score', ascending=False)\n",
    "\n",
    "display(bestfeatures.head(10))\n",
    "bestfeatures.plot.bar(x='feature', y='score',figsize=(70, 20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d616878",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pearson Correlation to identify strongest relationship to target\n",
    "features_to_drop = nonum_features + predict_features\n",
    "\n",
    "X = train_df.copy()\n",
    "X = X.drop(features_to_drop, axis=1)\n",
    "\n",
    "y = train_df[target_feature].copy()\n",
    "\n",
    "corr = X.corr()\n",
    "# corr = corr[(corr >= 0.8) & (corr != 1.0)].dropna(how='all').dropna(axis=1, how='all')\n",
    "cols = corr.loc[corr[target_feature] >= 0.7, target_feature].index\n",
    "corr = corr.loc[cols, cols]\n",
    "sns.heatmap(corr, annot=True, cmap='coolwarm')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf37a712",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kendall's method Correlation to identify strongest relationship to target\n",
    "# It takes a long time to run\n",
    "\n",
    "features_to_drop = nonum_features + predict_features\n",
    "\n",
    "X = train_df.copy()\n",
    "X = X.drop(features_to_drop, axis=1)\n",
    "\n",
    "y = train_df[target_feature].copy()\n",
    "\n",
    "corr = X.corr(method='kendall')\n",
    "# corr = corr[(corr >= 0.8) & (corr != 1.0)].dropna(how='all').dropna(axis=1, how='all')\n",
    "cols = corr.loc[corr[target_feature] >= 0.7, target_feature].index\n",
    "corr = corr.loc[cols, cols]\n",
    "sns.heatmap(corr, annot=True, cmap='coolwarm')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7e9b9122",
   "metadata": {},
   "source": [
    "Using NMME and other forecast data for improving prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e569ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Univariate Selection using NMME and other forecast data for improving prediction\n",
    "features_to_drop = nonum_features\n",
    "features_to_drop.append(target_feature)\n",
    "\n",
    "X = train_df.copy()\n",
    "X = X.drop(features_to_drop, axis=1)\n",
    "y = train_df[target_feature].copy()\n",
    "\n",
    "selector = SelectKBest(f_classif, k=10) # Top 30 features\n",
    "selector.fit(X, y)\n",
    "scores = selector.scores_\n",
    "\n",
    "bestfeatures = pd.DataFrame({'feature': X.columns, 'score': scores})\n",
    "bestfeatures = bestfeatures.sort_values(by='score', ascending=False)\n",
    "\n",
    "display(bestfeatures.head(10))\n",
    "bestfeatures.plot.bar(x='feature', y='score',figsize=(70, 20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8cc8e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recursive Feature Elimination (RFE) method\n",
    "features_to_drop = nonum_features\n",
    "features_to_drop.append(target_feature)\n",
    "\n",
    "X = train_df.copy()\n",
    "X = X.drop(features_to_drop, axis=1)\n",
    "y = train_df[target_feature].copy()\n",
    "\n",
    "reg = LinearRegression()\n",
    "\n",
    "rfe = RFE(reg, n_features_to_select=30)\n",
    "rfe.fit(X,y)\n",
    "\n",
    "bestfeatures = X.columns[rfe.support_]\n",
    "print(\"Best features :\", bestfeatures)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38683204",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recursive Feature Elimination (RFE) method without NMME features\n",
    "features_to_drop = nonum_features + predict_features\n",
    "features_to_drop.append(target_feature)\n",
    "\n",
    "X = train_df.copy()\n",
    "X = X.drop(features_to_drop, axis=1)\n",
    "y = train_df[target_feature].copy()\n",
    "\n",
    "reg = LinearRegression()\n",
    "\n",
    "rfe = RFE(reg, n_features_to_select=10)\n",
    "rfe.fit(X,y)\n",
    "\n",
    "bestfeatures = X.columns[rfe.support_]\n",
    "print(\"Best features :\", bestfeatures)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "36b4d4ec",
   "metadata": {},
   "source": [
    "##### Important features\n",
    "- Geopotential height\n",
    "- Evaporation\n",
    "- Precipitable water for entire atmosphere\n",
    "- Zonal wind\n",
    "- Longitudinal wind\n",
    "- Sea level pressure\n",
    "- Sea ice concentration\n",
    "- Month of the year\n",
    "- Day of the year\n",
    "\n",
    "Came up in RFE method\n",
    "- Humidity\n",
    "- MEI /NIP\n",
    "- MJO amplitude\n",
    "- Climate regions\n",
    "- year?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9964f968",
   "metadata": {},
   "source": [
    "##### Location Temperature Variation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ebc436",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = train_df[['location','startdate_ordinal','contest-tmp2m-14d__tmp2m']].copy()\n",
    "\n",
    "# Need to convert categorical data to numerical data\n",
    "temp_df['location']=pd.Categorical(temp_df['location'])\n",
    "temp_df['location']=temp_df['location'].cat.codes\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = plt.axes(projection='3d')\n",
    "ax.scatter3D(temp_df['location'], temp_df['startdate_ordinal'],  temp_df['contest-tmp2m-14d__tmp2m'], c=temp_df['contest-tmp2m-14d__tmp2m'], cmap=plt.cm.jet, linewidth=0.01)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "39ec6717",
   "metadata": {},
   "source": [
    "##### Yearly, Monthly, Daily Temperature Variation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d69ebeaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Yearly variation\n",
    "temp_df = train_df[['year','contest-tmp2m-14d__tmp2m']].copy()\n",
    "temp_df.plot.scatter(x='year',y='contest-tmp2m-14d__tmp2m', c=temp_df[target_feature], cmap=plt.cm.jet)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4a05e873",
   "metadata": {},
   "source": [
    "Temperature has risen by at least a couple of degrees as per yearly variation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "152d0fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Monthly variation\n",
    "temp_df = train_df[['month','contest-tmp2m-14d__tmp2m']].copy()\n",
    "temp_df.plot.scatter(x='month',y='contest-tmp2m-14d__tmp2m', c=temp_df[target_feature], cmap=plt.cm.jet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac7601b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Daily variation\n",
    "temp_df = train_df[['dayofyear','contest-tmp2m-14d__tmp2m']].copy()\n",
    "temp_df.plot.scatter(x='dayofyear',y='contest-tmp2m-14d__tmp2m', c=temp_df[target_feature], cmap=plt.cm.jet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62795014",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e984f72d",
   "metadata": {},
   "source": [
    "##### Elevation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "299fd146",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confirm if elevation is consistant for a location\n",
    "# elevation_df = train_df[['location','elevation__elevation']].drop_duplicates().copy()\n",
    "print('Unique combination of location and elevation are ',train_df[['location','elevation__elevation']].drop_duplicates().shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94474f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Elevation variation\n",
    "elevation_df = train_df[['elevation__elevation','contest-tmp2m-14d__tmp2m']].copy()\n",
    "elevation_df.plot.scatter(x='elevation__elevation',y='contest-tmp2m-14d__tmp2m', c=elevation_df[target_feature], cmap=plt.cm.jet)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a7a2fba9",
   "metadata": {},
   "source": [
    "The Effect of elevation is conjunction with latitude but overall understanding is that higher altitude leads to lower temperatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d468cee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Elevation Temperature variation over time\n",
    "elevation_df = train_df[['elevation__elevation','startdate','contest-tmp2m-14d__tmp2m']].copy()\n",
    "\n",
    "fig = plt.figure(dpi=300)\n",
    "ax = plt.axes(projection='3d')\n",
    "ax.plot_trisurf(elevation_df['elevation__elevation'], elevation_df['startdate'],  elevation_df['contest-tmp2m-14d__tmp2m'], cmap=plt.cm.jet, linewidth=0.01)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e716097",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize temperature against elevation over time\n",
    "# elevation_df = train_df[['elevation__elevation','startdate','contest-tmp2m-14d__tmp2m']].drop_duplicates().copy()\n",
    "\n",
    "elevations = elevation_df.elevation__elevation.unique()\n",
    "elevations.sort()\n",
    "\n",
    "# Plot temperature against elevation for a group of elevations \n",
    "# for e in itertools.islice(elevations, 40, 43):\n",
    "#     elevation_df_1 = elevation_df[elevation_df['elevation__elevation']==e]\n",
    "#     print('Elevation ',e)\n",
    "#     elevation_df_1.plot.line(x='startdate',y='contest-tmp2m-14d__tmp2m')\n",
    "\n",
    "# Plot temperature against elevation for a range of elevations\n",
    "for e in list(filter(lambda e: (e>=100 and e<=300), elevations)):\n",
    "    elevation_df_1 = elevation_df[elevation_df['elevation__elevation'] == e]\n",
    "    title_str = 'Elevation' + str(e)\n",
    "    elevation_df_1.plot.line(x='startdate',y='contest-tmp2m-14d__tmp2m',title=title_str)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "70f1153e",
   "metadata": {},
   "source": [
    "The effect of temperature with changing elevation is clear. Therefore this is an important feature."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "13db994f",
   "metadata": {},
   "source": [
    "##### Geopotential height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91240c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Geopotential height Temperature variation\n",
    "geoheight = 'contest-wind-h10-14d__wind-hgt-10'\n",
    "elevation_df = train_df[[geoheight,'contest-tmp2m-14d__tmp2m']].copy()\n",
    "elevation_df.plot.scatter(x=geoheight,y='contest-tmp2m-14d__tmp2m', c=elevation_df[target_feature], cmap=plt.cm.jet)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f1d49a69",
   "metadata": {},
   "source": [
    "Geopotential height is a much more reliable feature than elevation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e25c26d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Geopotential height Temperature variation over time\n",
    "geoheight = 'contest-wind-h10-14d__wind-hgt-10'\n",
    "elevation_df = train_df[[geoheight,'startdate','contest-tmp2m-14d__tmp2m']].copy()\n",
    "\n",
    "fig = plt.figure(dpi=300)\n",
    "ax = plt.axes(projection='3d')\n",
    "ax.plot_trisurf(elevation_df[geoheight], elevation_df['startdate'],  elevation_df['contest-tmp2m-14d__tmp2m'], cmap=plt.cm.jet, linewidth=0.01)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9ab0b788",
   "metadata": {},
   "source": [
    "##### Evaporation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9d211b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaporation Temperature variation\n",
    "evaporation = 'contest-pevpr-sfc-gauss-14d__pevpr'\n",
    "eva_df = train_df[[evaporation,target_feature]].copy()\n",
    "eva_df.plot.scatter(x=evaporation,y=target_feature, c=eva_df[target_feature], cmap=plt.cm.jet)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0326d47f",
   "metadata": {},
   "source": [
    "##### Precipitable water"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff96ed65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Precipitable water Temperature variation\n",
    "prwtr_df = train_df[['contest-prwtr-eatm-14d__prwtr',target_feature]].copy()\n",
    "prwtr_df.plot.scatter(x='contest-prwtr-eatm-14d__prwtr',y=target_feature, c=prwtr_df[target_feature], cmap=plt.cm.jet)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "eb6f5799",
   "metadata": {},
   "source": [
    "##### Precipitation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f6af981",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Precipitation Temperature variation\n",
    "prec_df = train_df[['contest-precip-14d__precip',target_feature]].copy()\n",
    "prec_df.plot.scatter(x='contest-precip-14d__precip',y=target_feature, c=prec_df[target_feature], cmap=plt.cm.jet)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6c867c0a",
   "metadata": {},
   "source": [
    "##### Relative Humidity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14081a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Relative Humidity Temperature variation\n",
    "hum_df = train_df[['contest-precip-14d__precip',target_feature]].copy()\n",
    "hum_df.plot.scatter(x='contest-precip-14d__precip',y=target_feature, c=hum_df[target_feature], cmap=plt.cm.jet)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "68f178a6",
   "metadata": {},
   "source": [
    "##### Zonal wind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c2b5b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zonal wind Temperature variation\n",
    "uwind = 'contest-wind-uwnd-925-14d__wind-uwnd-925'\n",
    "wind_df = train_df[[uwind,target_feature]].copy()\n",
    "wind_df.plot.scatter(x=uwind,y=target_feature, c=wind_df[target_feature], cmap=plt.cm.jet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2817464c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zonal wind Temperature variation over location\n",
    "uwind = 'contest-wind-uwnd-925-14d__wind-uwnd-925'\n",
    "wind_df = train_df[[uwind,'location','contest-tmp2m-14d__tmp2m']].copy()\n",
    "\n",
    "\n",
    "# Need to convert categorical data to numerical data\n",
    "wind_df['location']=pd.Categorical(wind_df['location'])\n",
    "wind_df['location']=wind_df['location'].cat.codes\n",
    "\n",
    "fig = plt.figure(dpi=300)\n",
    "ax = plt.axes(projection='3d')\n",
    "ax.plot_trisurf(wind_df[uwind], wind_df['location'], wind_df['contest-tmp2m-14d__tmp2m'], cmap=plt.cm.jet, linewidth=0.01)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8056ede8",
   "metadata": {},
   "source": [
    "There is a tendency of decrease in temperature due to higher zonal wind speed"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c8659fa9",
   "metadata": {},
   "source": [
    "##### Longitudinal Wind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ea43f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Longitudinal wind Temperature variation\n",
    "vwind = 'contest-wind-vwnd-250-14d__wind-vwnd-250'\n",
    "wind_df = train_df[[vwind,target_feature]].copy()\n",
    "wind_df.plot.scatter(x=vwind,y=target_feature, c=wind_df[target_feature], cmap=plt.cm.jet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "031697dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Longitudinal wind Temperature variation over location\n",
    "vwind = 'contest-wind-vwnd-250-14d__wind-vwnd-250'\n",
    "wind_df = train_df[[vwind,'location','contest-tmp2m-14d__tmp2m']].copy()\n",
    "\n",
    "\n",
    "# Need to convert categorical data to numerical data\n",
    "wind_df['location']=pd.Categorical(wind_df['location'])\n",
    "wind_df['location']=wind_df['location'].cat.codes\n",
    "\n",
    "fig = plt.figure(dpi=300)\n",
    "ax = plt.axes(projection='3d')\n",
    "ax.plot_trisurf(wind_df[vwind], wind_df['location'], wind_df['contest-tmp2m-14d__tmp2m'], cmap=plt.cm.jet, linewidth=0.01)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f0232a6e",
   "metadata": {},
   "source": [
    "There is a tendency of rise in temperature with lower wind speed. Negative direction is more cooler"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7062343c",
   "metadata": {},
   "source": [
    "##### Climate Region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "505e0f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Climate region Temperature variation\n",
    "climate_df = train_df[['climateregions__climateregion','contest-tmp2m-14d__tmp2m']].copy()\n",
    "climate_df.plot.scatter(x='climateregions__climateregion',y='contest-tmp2m-14d__tmp2m', c=elevation_df[target_feature], cmap=plt.cm.jet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61a040eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Climate region temperature variation - monthly\n",
    "climate_df = train_df[['climateregions__climateregion','month','contest-tmp2m-14d__tmp2m']].drop_duplicates().copy()\n",
    "\n",
    "# Need to convert categorical data to numerical data\n",
    "climate_df['climateregions__climateregion']=pd.Categorical(climate_df['climateregions__climateregion'])\n",
    "climate_df['climateregions__climateregion']=climate_df['climateregions__climateregion'].cat.codes\n",
    "\n",
    "fig = plt.figure(dpi=200)\n",
    "ax = plt.axes(projection='3d')\n",
    "ax.scatter3D(climate_df['climateregions__climateregion'], climate_df['month'],  climate_df['contest-tmp2m-14d__tmp2m'], c=climate_df['contest-tmp2m-14d__tmp2m'], cmap=plt.cm.jet, linewidth=0.01)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b7cb41d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot effect of climate region on temperature over time\n",
    "climate_df = train_df[['climateregions__climateregion','startdate','contest-tmp2m-14d__tmp2m']].drop_duplicates().copy()\n",
    "\n",
    "climates = climate_df.climateregions__climateregion.unique()\n",
    "display(print('Unique climate regions ',len(climates)))\n",
    "\n",
    "for e in climates:\n",
    "    climate_df_1 = climate_df[climate_df['climateregions__climateregion'] == e]\n",
    "    title_str = 'Climate region ' + e\n",
    "    climate_df_1.plot.line(x='startdate',y='contest-tmp2m-14d__tmp2m',title=title_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "491d34ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combined plot using plotly express\n",
    "\n",
    "fig = px.line(climate_df, x='startdate', \n",
    "              y='contest-tmp2m-14d__tmp2m', \n",
    "              color = 'climateregions__climateregion', \n",
    "              facet_row='climateregions__climateregion',facet_row_spacing=0.04,\n",
    "              labels={\"contest-tmp2m-14d__tmp2m\":\"Temp\", \"climateregions__climateregion\":\"Climate Region\"},\n",
    "              template = 'plotly_white', height=2000)\n",
    "\n",
    "fig.update_layout(title='Mean temperature variations by climate regions', xaxis_title='Date')\n",
    "fig.update_yaxes(visible=True, matches=None)\n",
    "fig.update_layout(annotations=[], overwrite=True)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "42070cf7",
   "metadata": {},
   "source": [
    "The effect of climate region on temperature is evident from the plots. But the effect has lower correlation than other factors. Therefore this is a semi important feature."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3f29268c",
   "metadata": {},
   "source": [
    "##### Pressure and Sea Level Pressure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d8bd11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Atmospheric pressure Temperature variation\n",
    "prs_df = train_df[['contest-pres-sfc-gauss-14d__pres',target_feature]].copy()\n",
    "prs_df.plot.scatter(x='contest-pres-sfc-gauss-14d__pres',y=target_feature, c=prs_df[target_feature], cmap=plt.cm.jet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "380755f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sea level pressure Temperature variation\n",
    "prs_df = train_df[['contest-slp-14d__slp',target_feature]].copy()\n",
    "prs_df.plot.scatter(x='contest-slp-14d__slp',y=target_feature, c=prs_df[target_feature], cmap=plt.cm.jet)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6a648300",
   "metadata": {},
   "source": [
    "Atmospheric pressure and Sea level pressure are directly proportional to temperature, but the data doesn't show that!!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e63f7f0c",
   "metadata": {},
   "source": [
    "#####  Multivariate ENSO index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45719675",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize effect of El Niño on temperature\n",
    "print('Unique combination of location and NIP are ',train_df[['location','mei__nip']].drop_duplicates().shape[0])\n",
    "print('Unique combination of location and MEI are ',train_df[['location','mei__mei']].drop_duplicates().shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe5fcdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize effect of El Niño on temperature\n",
    "mei_df = train_df[['mei__meirank','contest-tmp2m-14d__tmp2m']].copy()\n",
    "mei_df.plot.scatter(x='mei__meirank',y='contest-tmp2m-14d__tmp2m', c=elevation_df[target_feature], cmap=plt.cm.jet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91547661",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize effect of El Niño on temperature over time\n",
    "mei_df = train_df[['mei__mei','startdate_ordinal','contest-tmp2m-14d__tmp2m']].drop_duplicates().copy()\n",
    "\n",
    "meis = mei_df.mei__mei.unique()\n",
    "meis.sort()\n",
    "\n",
    "fig = plt.figure(dpi=200)\n",
    "ax = plt.axes(projection='3d')\n",
    "ax.scatter3D(mei_df['mei__mei'], mei_df['startdate_ordinal'],  mei_df['contest-tmp2m-14d__tmp2m'], c=mei_df['contest-tmp2m-14d__tmp2m'], cmap=plt.cm.jet, linewidth=0.01)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "511d15b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize temperature against MEI\n",
    "mei_df = train_df[['mei__mei','startdate','contest-tmp2m-14d__tmp2m']].drop_duplicates().copy()\n",
    "\n",
    "meis = mei_df.mei__mei.unique()\n",
    "meis.sort()\n",
    "\n",
    "# Plot temperature against elevation for a range of MEI\n",
    "for e in list(filter(lambda e: (e>=0 and e<=0.5), meis)):\n",
    "    mei_df_1 = mei_df[mei_df['mei__mei'] == e]\n",
    "    title_str = 'MEI ' + str(e)\n",
    "    mei_df_1.plot.line(x='startdate',y='contest-tmp2m-14d__tmp2m',title=title_str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9f48bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize temperature against Nino Index Phase\n",
    "nip_df = train_df[['mei__nip','startdate','contest-tmp2m-14d__tmp2m']].copy()\n",
    "\n",
    "fig = px.line(nip_df, x='startdate', \n",
    "              y='contest-tmp2m-14d__tmp2m', \n",
    "              color = 'mei__nip', \n",
    "              facet_row='mei__nip',facet_row_spacing=0.04,\n",
    "              labels={\"contest-tmp2m-14d__tmp2m\":\"Temp\", \"mei__nip\":\"NIP\"},\n",
    "              template = 'plotly_white', height=300)\n",
    "\n",
    "fig.update_layout(title='Mean temperature variations by NIP', xaxis_title='Date')\n",
    "fig.update_yaxes(visible=True, matches=None)\n",
    "fig.update_layout(annotations=[], overwrite=True)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "074b19d9",
   "metadata": {},
   "source": [
    "Effect of MEI and NIP is not clearly visible, although slight increase in temperature is evident with nigher NIP. This is a secondary feature."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "76089083",
   "metadata": {},
   "source": [
    "##### Madden-Julian Oscillation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a593c5f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize effect of MJO on temperature\n",
    "print('Unique combination of location and MJO Amplitude are ',train_df[['location','mjo1d__amplitude']].drop_duplicates().shape[0])\n",
    "print('Unique combination of location and MJO Phase are ',train_df[['location','mjo1d__phase']].drop_duplicates().shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0233f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize effect of MJO on temperature\n",
    "mjo_df = train_df[['mjo1d__phase','contest-tmp2m-14d__tmp2m']].copy()\n",
    "mjo_df.plot.scatter(x='mjo1d__phase',y='contest-tmp2m-14d__tmp2m', c=elevation_df[target_feature], cmap=plt.cm.jet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a847423b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize effect of MJO on temperature over time\n",
    "mjo_df = train_df[['mjo1d__phase','startdate_ordinal','contest-tmp2m-14d__tmp2m']].drop_duplicates().copy()\n",
    "\n",
    "meis = mjo_df.mjo1d__phase.unique()\n",
    "meis.sort()\n",
    "\n",
    "fig = plt.figure(dpi=200)\n",
    "ax = plt.axes(projection='3d')\n",
    "ax.scatter3D(mjo_df['mjo1d__phase'], mjo_df['startdate_ordinal'],  mjo_df['contest-tmp2m-14d__tmp2m'], c=mjo_df['contest-tmp2m-14d__tmp2m'], cmap=plt.cm.jet, linewidth=0.01)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f3be51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize temperature against MJO Phase\n",
    "mjo_df = train_df[['mjo1d__phase','startdate','contest-tmp2m-14d__tmp2m']].drop_duplicates().copy()\n",
    "\n",
    "mjos = mjo_df.mjo1d__phase.unique()\n",
    "mjos.sort()\n",
    "\n",
    "# Plot temperature against elevation for a range of MEI\n",
    "# for e in list(filter(lambda e: (e>=3 and e<=7), mjos)):\n",
    "#     mjo_df_1 = mjo_df[mjo_df['mjo1d__phase'] == e]\n",
    "#     title_str = 'MJO Phase ' + str(e)\n",
    "#     mjo_df_1.plot.line(x='startdate',y='contest-tmp2m-14d__tmp2m',title=title_str)\n",
    "\n",
    "fig = px.line(mjo_df, x='startdate', \n",
    "              y='contest-tmp2m-14d__tmp2m', \n",
    "              color = 'mjo1d__phase', \n",
    "              facet_row='mjo1d__phase',facet_row_spacing=0.04,\n",
    "              labels={\"contest-tmp2m-14d__tmp2m\":\"Temp\", \"mjo1d__phase\":\"MJO\"},\n",
    "              template = 'plotly_white', height=2000)\n",
    "\n",
    "fig.update_layout(title='Mean temperature variations by MJO Phase', xaxis_title='Date')\n",
    "fig.update_yaxes(visible=True, matches=None)\n",
    "fig.update_layout(annotations=[], overwrite=True)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0ddf6c67",
   "metadata": {},
   "source": [
    "Effect of MJO is not clearly visible, although slight increase in temperature is evident with nigher MJO phase. This is a secondary feature."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5c77aa9d",
   "metadata": {},
   "source": [
    "##### Sea Surface Temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab9afa8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize effect of Sea Surface Temperature on temperature\n",
    "print('Unique combination of location and Sea Surface Temperature are ',train_df[['location','sst-2010-8']].drop_duplicates().shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "764d5e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize temperature against Sea Surface Temperature\n",
    "sst = 'sst-2010-1'\n",
    "sst_df = train_df[[sst,'startdate_ordinal','contest-tmp2m-14d__tmp2m']].drop_duplicates().copy()\n",
    "\n",
    "ssts = sst_df[sst].unique()\n",
    "ssts.sort()\n",
    "\n",
    "fig = plt.figure(dpi=200)\n",
    "ax = plt.axes(projection='3d')\n",
    "ax.scatter3D(sst_df[sst], sst_df['startdate_ordinal'],  sst_df['contest-tmp2m-14d__tmp2m'], c=sst_df['contest-tmp2m-14d__tmp2m'], cmap=plt.cm.jet, linewidth=0.01)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d9ff0a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize temperature against Sea Surface Temperature\n",
    "loc = 'POINT (0.6818180000000000 0.8333330000000000)' #checking by a location\n",
    "sst = 'sst-2010-1'\n",
    "\n",
    "sst_df = train_df[['location',sst,'startdate_ordinal','contest-tmp2m-14d__tmp2m']].drop_duplicates().copy()\n",
    "sst_df = sst_df[sst_df['location']==loc]\n",
    "\n",
    "fig = plt.figure(dpi=200)\n",
    "ax = plt.axes(projection='3d')\n",
    "ax.scatter3D(sst_df[sst], sst_df['startdate_ordinal'],  sst_df['contest-tmp2m-14d__tmp2m'], c=sst_df['contest-tmp2m-14d__tmp2m'], cmap=plt.cm.jet, linewidth=0.01)\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "06304ea5",
   "metadata": {},
   "source": [
    "Increase in the Sea Surface Temperature causes increase in Temperature. This is an important feature"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "237880c1",
   "metadata": {},
   "source": [
    "##### Sea Ice Concentration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "512ec1e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize temperature against Sea Ice Concentration\n",
    "icec = 'icec-2010-1'\n",
    "icec_df = train_df[[icec,'startdate_ordinal','contest-tmp2m-14d__tmp2m']].drop_duplicates().copy()\n",
    "\n",
    "icecs = icec_df[icec].unique()\n",
    "icecs.sort()\n",
    "\n",
    "fig = plt.figure(dpi=200)\n",
    "ax = plt.axes(projection='3d')\n",
    "ax.scatter3D(icec_df[icec], icec_df['startdate_ordinal'],  icec_df['contest-tmp2m-14d__tmp2m'], c=icec_df['contest-tmp2m-14d__tmp2m'], cmap=plt.cm.jet, linewidth=0.01)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b92fa51c",
   "metadata": {},
   "source": [
    "##### NMME prediction comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42aa5888",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NMME Temperature comparison with actual\n",
    "loc = 'POINT (1.0000000000000000 0.6000000000000000)' #checking by a location\n",
    "nmme_temp = 'nmme0mean'\n",
    "\n",
    "temp_df = train_df[['location','startdate',nmme_temp,target_feature]].copy()\n",
    "temp_df = temp_df[temp_df['location']==loc]\n",
    "temp_df['difference'] = temp_df[nmme_temp]-temp_df[target_feature]\n",
    "\n",
    "temp_df.plot.bar(x='startdate',y='difference')\n",
    "# temp_df.plot.scatter(x='startdate_ordinal',y='difference')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2f2d7981",
   "metadata": {},
   "source": [
    "The NMME predictions are off to various degrees in both positive and negative direction. This poses a question on whether this data should be used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7c0e527e",
   "metadata": {},
   "source": [
    "##### Additional important features\n",
    "- Elevation\n",
    "- Sea Surface Temperature\n",
    "- Climate Region"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "be82cb28",
   "metadata": {},
   "source": [
    "#### Inferences\n",
    "- NMME forecast data have the strongest correlation to the target as per various feature selection algorithms\n",
    "- The algorithms are contradictory about feature selection in some cases!\n",
    "- The common weather forecast parameters are not considered by the algorithms!\n",
    "- If individually compared the data sometimes doesn't correlate strongly where ideally it should as per meteorological equations!\n",
    "- There are too many features in the dataset and choosing features for modelling is a challenging task\n",
    "- Any of the following strategies may be followed - \n",
    "    - Select the results of the feature selection algorithms which puts heavy preference on NMME forecast data\n",
    "    - Select known meteorological parameters which affect temperature and ignore NMME forecast data\n",
    "    - Combine from both feature selection algorithm results and meteorological parameters\n",
    "- Next question to answer how many features to be considered?\n",
    "- Many features have multiple measurements from different methods. Should all be considered or only one or select few?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0400ba89",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "633ce6e2",
   "metadata": {},
   "source": [
    "## Modelling"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0ec2761e",
   "metadata": {},
   "source": [
    "#### Multiple Linear Regression"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a59bd37c",
   "metadata": {},
   "source": [
    "#### Gradient Descent Optimization"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c1920723",
   "metadata": {},
   "source": [
    "#### Non-Linear Regression"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5bd07f73",
   "metadata": {},
   "source": [
    "#### K-Nearest-Neighbour algorithm"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b2e57b0d",
   "metadata": {},
   "source": [
    "#### K Means Clustering Algorithm"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "611ddffb",
   "metadata": {},
   "source": [
    "#### Artificial Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d52b99c",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "vscode": {
   "interpreter": {
    "hash": "c261aea317cc0286b3b3261fbba9abdec21eaa57589985bb7a274bf54d6cc0a7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
